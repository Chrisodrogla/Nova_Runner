# main.yml
name: Sample_Run_Test

on:
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Split rental links into batches
      run: |
        mkdir -p batches
        python -c "
import json
import os

with open('scraper/scraper/Listing_Url/final_rental_link.json', 'r') as f:
    rental_links = json.load(f)

batch_size = 3
for i in range(0, len(rental_links), batch_size):
    batch = rental_links[i:i+batch_size]
    with open(f'batches/batch_{i//batch_size}.json', 'w') as bf:
        json.dump(batch, bf, indent=2)
"

    - name: Run scraper scripts in parallel
      run: |
        for batch_file in batches/*.json; do
          python scraper/scraper/Listing_Url/scrape_batch.py $batch_file &
        done
        wait

    - name: Collect results
      run: |
        mkdir -p results
        mv batches/*_results.json results/
        echo "Scraping completed. Results saved in results/ directory."
